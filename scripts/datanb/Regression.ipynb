{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "did_tid = {41021: 167210, 550: 359930, 546: 359931, 541: 359932, 507: 359933, 505: 359934, 287: 359935, 216: 359936, 42705: 317614, 42571: 233212, 41540: 359937, 42225: 233211, 42708: 317613, 42688: 359938, 42572: 233214, 42570: 233215, 422: 359939, 416: 359940, 3050: 13854, 3277: 14097, 42724: 359941, 42721: 359926, 42727: 359942, 42729: 359943, 42726: 359944, 42730: 359945, 201: 359946, 4549: 233213, 41702: 359947, 41980: 359948, 42731: 359949, 531: 359950, 42563: 359951, 574: 359952}\n",
    "regression_datasets = list(did_tid)\n",
    "datasets, = openml.datasets.list_datasets(regression_datasets, output_format=\"dataframe\"),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['did', 'name', 'version', 'uploader', 'status', 'format',\n",
       "       'NumberOfClasses', 'NumberOfFeatures', 'NumberOfInstances',\n",
       "       'NumberOfInstancesWithMissingValues', 'NumberOfMissingValues',\n",
       "       'NumberOfNumericFeatures', 'NumberOfSymbolicFeatures',\n",
       "       'MaxNominalAttDistinctValues'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import mpld3\n",
    "import numpy as np\n",
    "mpld3.enable_notebook()\n",
    "\n",
    "\n",
    "from warnings import simplefilter\n",
    "from matplotlib.cbook.deprecation import MatplotlibDeprecationWarning\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=MatplotlibDeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code allows you to explore the dataset characteristics, you need to first click on of the UI controls so that the plot is updated and shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35ab934912624bee9b5142b31b557883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(SelectMultiple(description='Exclude', index=(0,), options=('None', 'pol', 'elevaâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_var = widgets.Select(\n",
    "    options=list(datasets.columns),\n",
    "    value=\"NumberOfInstances\",\n",
    "    rows=1,\n",
    "    description='X:',\n",
    ")\n",
    "\n",
    "y_var = widgets.Select(\n",
    "    options=list(datasets.columns),\n",
    "    value=\"NumberOfFeatures\",\n",
    "    rows=1,\n",
    "    description='Y:',\n",
    ")\n",
    "\n",
    "log_x = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='log x',\n",
    "    disabled=False,\n",
    "    indent=False,\n",
    "    layout=Layout(width=\"75px\"),\n",
    ")\n",
    "\n",
    "log_y = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='log y',\n",
    "    disabled=False,\n",
    "    indent=False,\n",
    "    layout=Layout(width=\"75px\"),\n",
    ")\n",
    "\n",
    "exclude = widgets.SelectMultiple(\n",
    "    options=[\"None\"] + list(datasets[\"name\"]),\n",
    "    value=[\"None\"],\n",
    "    description='Exclude',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "suite = widgets.Select(\n",
    "    options=[\"Regression\", \"Classification\", \"Classification (old)\", \"Classification (new)\"],\n",
    "    value=\"Regression\",\n",
    "    rows=1,\n",
    "    description='Set:',\n",
    ")\n",
    "\n",
    "exclude.options = [\"None\"] + list(datasets[\"name\"])\n",
    "exclude.value = [\"None\"]\n",
    "\n",
    "def plot(x, y, logx, logy, exclude):\n",
    "    fig, ax = plt.subplots()\n",
    "    filtered = datasets[~datasets[\"name\"].isin(exclude)]\n",
    "    # for some reason ax.set(xscale=\"log\") does not work and shows points all over.\n",
    "    xval = np.log10(filtered[x]) if logx else filtered[x]\n",
    "    yval = np.log10(filtered[y]) if logy else filtered[y]\n",
    "    ax = sns.scatterplot(x=xval, y=yval, data=filtered, ax=ax)\n",
    "    ax.yaxis.labelpad = 25\n",
    "    ax.xaxis.labelpad = 5\n",
    "    labels=[f\"{name} ({xi}, {yi})\" for name, xi, yi in zip(filtered[\"name\"], filtered[x], filtered[y])\n",
    "            if not (np.isnan(xi) or np.isnan(yi))]\n",
    "    tooltip = mpld3.plugins.PointLabelTooltip(ax.get_children()[0], labels=labels)\n",
    "    mpld3.plugins.connect(fig, tooltip)\n",
    "\n",
    "\n",
    "out = widgets.interactive_output(plot, {'x': x_var, 'y': y_var, 'logx': log_x, 'logy': log_y, 'exclude': exclude})\n",
    "widgets.HBox([widgets.VBox([exclude, x_var, y_var, widgets.HBox([log_x, log_y])]), out])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Potential Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: 4 House datasets\n",
    "This selection contains the following four housing datasets (in addition to a house rent price dataset):\n",
    "\n",
    "| Dataset  | N (rows) | P (cols)  | Used in  | Source  | openml id |\n",
    "|---|---|---|---|---|---|\n",
    "| House_16H  | 22784   | 17  | Balaji  | 1990 Census USA  | 574 |\n",
    "| Boston  | 506  | 14  | Balaji  | Boston 1970s | 531 |\n",
    "| house_price_nominal  | 1460  | 80  | AutoGluon  | Iowa 2006-2010  | 42563 |\n",
    "| king county  |  21613 | 20  | mlr3  | KC (Seattle) 2014-2015  | 42092 |\n",
    "\n",
    "They are from different times and different regions, which isn't necessarily problematic. With the total suite size of 30-35 datasets it would be a very dominating category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Lack of meta-data\n",
    "Some datasets lack interpretability of the problem. This is true for both AutoML ChaLearn challenges (Flora & Yolanda). It has also been identified as an issue for [pol](https://www.openml.org/d/201) (and for [Buzzinsocialmedia_Twitter](https://www.openml.org/d/4549) meta-data needs to be translated from French)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Runtime Prediction Datasets\n",
    "[MIP-2016-Regression](https://www.openml.org/d/41702) and [SAT-hand-runtime-regression](https://www.openml.org/d/41980) are algorithm selection/runtime prediction datasets. Each dataset features 5-15 algorithms which is run on 200-300 problems, which would make 10-fold CV a less than optimal evaluation procedure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
